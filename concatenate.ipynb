{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### CONCATENATE ALL FILES EXCEL ##########################\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Folder containing your AHJ Excel files\n",
    "folder = 'clean'\n",
    "files = [f for f in os.listdir(folder) if f.endswith('.csv')]\n",
    "\n",
    "# Track results\n",
    "valid_dfs = []\n",
    "missing_clean = []\n",
    "load_errors = []\n",
    "header_mismatches = []\n",
    "\n",
    "# Check all files\n",
    "for file in files:\n",
    "    path = os.path.join(folder, file)\n",
    "    try:\n",
    "        xls = pd.ExcelFile(path)\n",
    "        if 'Clean' not in xls.sheet_names:\n",
    "            missing_clean.append(file)\n",
    "            continue\n",
    "\n",
    "        df = pd.read_excel(path, sheet_name='Clean')\n",
    "\n",
    "        df_cols = set(df.columns)\n",
    "        std_cols = set(standard_columns)\n",
    "\n",
    "        if df_cols == std_cols:\n",
    "            # Reorder and store\n",
    "            df = df[standard_columns]\n",
    "            valid_dfs.append(df)\n",
    "        else:\n",
    "            # Find differences\n",
    "            missing = list(std_cols - df_cols)\n",
    "            extra = list(df_cols - std_cols)\n",
    "            header_mismatches.append({\n",
    "                'file': file,\n",
    "                'missing': missing,\n",
    "                'extra': extra\n",
    "            })\n",
    "\n",
    "    except Exception as e:\n",
    "        load_errors.append((file, str(e)))\n",
    "\n",
    "# ‚úÖ Merge valid files\n",
    "if valid_dfs:\n",
    "    combined_df = pd.concat(valid_dfs, ignore_index=True)\n",
    "    combined_df.to_csv('Clean_merged.csv', index=False)\n",
    "    print(f\"\\n‚úÖ Successfully merged {len(valid_dfs)} files into 'Clean_merged.xlsx' with {len(combined_df)} rows.\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No valid files found for merging.\")\n",
    "\n",
    "# ‚ö†Ô∏è Report mismatches\n",
    "if header_mismatches:\n",
    "    print(\"\\n‚ö†Ô∏è Files with missing or extra columns:\")\n",
    "    for entry in header_mismatches:\n",
    "        print(f\" - {entry['file']}\")\n",
    "        if entry['missing']:\n",
    "            print(f\"   Missing: {entry['missing']}\")\n",
    "        if entry['extra']:\n",
    "            print(f\"   Extra:   {entry['extra']}\")\n",
    "\n",
    "# ‚ö†Ô∏è Files missing Clean sheet\n",
    "if missing_clean:\n",
    "    print(\"\\n‚ö†Ô∏è Files missing 'Clean' sheet:\")\n",
    "    for f in missing_clean:\n",
    "        print(f\" - {f}\")\n",
    "\n",
    "# ‚ùå Load errors\n",
    "if load_errors:\n",
    "    print(\"\\n‚ùå Files that failed to load:\")\n",
    "    for f, err in load_errors:\n",
    "        print(f\" - {f}: {err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### STANDARIZE DATA FORMAT FINAL FILE #######################\n",
    "\n",
    "# CSV version of the file\n",
    "file = 'Clean_merged.csv'  # Replace with your file name\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # üîç Auto-detect columns with 'date' in the name\n",
    "    date_cols = [col for col in df.columns if 'date' in col.lower()]\n",
    "\n",
    "    for col in date_cols:\n",
    "        try:\n",
    "            df[col] = pd.to_datetime(df[col], errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "            print(f\"‚úÖ Standardized column: {col}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Could not convert column {col}: {e}\")\n",
    "\n",
    "    # Save cleaned CSV\n",
    "    df.to_csv('Clean_test_output.csv', index=False)\n",
    "    print(\"üìÅ Saved cleaned file as 'Clean_test_output.csv'\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error processing file: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ Summary ####################\n",
    "\n",
    "# Path to your file\n",
    "file_path = \"Clean_test_output.csv\"\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Generate summary\n",
    "print(\"üîç DATASET SUMMARY\")\n",
    "print(f\"Total rows: {len(df)}\")\n",
    "print(f\"Total columns: {len(df.columns)}\\n\")\n",
    "\n",
    "print(\"üìå Column names:\")\n",
    "print(df.columns.tolist(), \"\\n\")\n",
    "\n",
    "print(\"üìä Data types:\")\n",
    "print(df.dtypes, \"\\n\")\n",
    "\n",
    "print(\"‚ùì Missing values per column:\")\n",
    "print(df.isnull().sum(), \"\\n\")\n",
    "\n",
    "print(\"üî¢ Sample data:\")\n",
    "print(df.head(), \"\\n\")\n",
    "\n",
    "print(\"üß© Unique values (up to 5 per column):\")\n",
    "for col in df.columns:\n",
    "    uniques = df[col].dropna().unique()[:5]\n",
    "    print(f\"{col}: {uniques}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9532e42613248e3bea74a451200a3a73d234b77f0e55931a71c29d0623a5ca48"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
